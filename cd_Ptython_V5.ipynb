{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "479e3a35-b8ad-4e81-959b-c0aa4401e17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "Iniciando Cálculo de Promedios Anuales por Ciudad\n",
      "=======================================================\n",
      "\n",
      "[PASO 1] Leyendo y Limpiando filas crudas en paralelo...\n",
      "\n",
      "[PROCESAMIENTO PARALELO] Usando 8 núcleos para 11 bloques.\n",
      "-------------------------------------------------------\n",
      "   Tiempo de lectura y limpieza paralela: 4.6973 segundos\n",
      "   Filas crudas válidas consolidadas: 992,090 filas.\n",
      "-------------------------------------------------------\n",
      "\n",
      "[PASO 2] Aplicando Fórmula de Promedio Anual...\n",
      "  Tiempo de cálculo de promedios: 0.5525 segundos\n",
      "  Registros de promedios anuales: 2,912 registros (Resultado de la agregación).\n",
      "-------------------------------------------------------\n",
      "\n",
      "[PASO 3] Depuración (QuickSort-style) de los promedios...\n",
      "   Tiempo de depuración: 0.0016 segundos\n",
      "   Promedios finales a ordenar: 2,912 registros.\n",
      "-------------------------------------------------------\n",
      "\n",
      "[PASO 4] Ordenamiento (Merge Sort) de los promedios...\n",
      "  Tiempo de ordenamiento: 0.0170 segundos\n",
      "-------------------------------------------------------\n",
      "\n",
      "[PASO 5] Generando archivo CSV: procesamiento_paralelo_python_promedios.csv\n",
      "  Tiempo de escritura: 0.0116 segundos\n",
      "\n",
      "=======================================================\n",
      " PROCESO COMPLETADO. Tiempo total: 5.2838 segundos.\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import time\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "from itertools import chain\n",
    "\n",
    "# Aumentar el límite del campo CSV, esencial para archivos grandes\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# --- ALGORITMOS DE ORDENAMIENTO Y DEPURACIÓN ---\n",
    "\n",
    "def merge_sort(arr):\n",
    "    if len(arr) <= 1:\n",
    "        return arr\n",
    "    mid = len(arr) // 2\n",
    "    left = merge_sort(arr[:mid])\n",
    "    right = merge_sort(arr[mid:])\n",
    "    return merge(left, right)\n",
    "\n",
    "def merge(left, right):\n",
    "    result = []\n",
    "    i = j = 0\n",
    "    while i < len(left) and j < len(right):\n",
    "        # Criterio de ordenamiento: de mayor a menor temperatura\n",
    "        if left[i][2] >= right[j][2]:\n",
    "            result.append(left[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            result.append(right[j])\n",
    "            j += 1\n",
    "    result.extend(left[i:])\n",
    "    result.extend(right[j:])\n",
    "    return result\n",
    "\n",
    "# Quick Sort para depurar: filtra valores no numéricos o 0.0\n",
    "def depurar_y_particionar(arr):\n",
    "    n = len(arr)\n",
    "    i = -1\n",
    "    for j in range(n):\n",
    "        temp_val = arr[j][2]\n",
    "        # Aplica la depuración sobre los promedios calculados\n",
    "        if isinstance(temp_val, (int, float)) and temp_val != 0.0:\n",
    "            i += 1\n",
    "            arr[i], arr[j] = arr[j], arr[i]\n",
    "    return i + 1\n",
    "\n",
    "# --- IMPLEMENTACIÓN DE LA FÓRMULA DE PROMEDIO ANUAL (Lógica Java) ---\n",
    "\n",
    "def calcular_promedios_anuales(datos_list):\n",
    "    \"\"\"\n",
    "    Calcula la temperatura promedio anual por ciudad usando la lógica de HashMap.\n",
    "    Recibe: Lista de tuplas (Ciudad, Año, Temp).\n",
    "    Devuelve: Lista de tuplas (Ciudad, Año, Promedio).\n",
    "    \"\"\"\n",
    "    # map para guardar la suma de las temperaturas de ciudad-anio\n",
    "    sumas = {}\n",
    "    # conteo de dias por ciudad\n",
    "    conteos = {}\n",
    "\n",
    "    for ciudad, anio, temp in datos_list:\n",
    "        clave = f\"{ciudad}|{anio}\"\n",
    "\n",
    "        # Lógica para sumar las temperaturas\n",
    "        # Si la clave existe, actualiza; si no, inicializa.\n",
    "        sumas[clave] = sumas.get(clave, 0.0) + temp\n",
    "        \n",
    "        # Lógica para contar los días\n",
    "        # Si la clave existe, incrementa; si no, inicializa a 1.\n",
    "        conteos[clave] = conteos.get(clave, 0) + 1\n",
    "\n",
    "    lista_promedios = []\n",
    "\n",
    "    # Por cada clave, aplica la fórmula: Promedio = Suma / Conteo\n",
    "    for clave in sumas.keys():\n",
    "        suma_total = sumas[clave]\n",
    "        cantidad_dias = conteos[clave]\n",
    "\n",
    "        # FÓRMULA: Suma de Temperaturas / N (Días)\n",
    "        promedio = suma_total / cantidad_dias\n",
    "\n",
    "        # Descomponer la clave\n",
    "        ciudad, anio = clave.split(\"|\")\n",
    "\n",
    "        # Agregar el nuevo registro de promedio anual\n",
    "        # Formato (Ciudad, Año, Promedio) para que sea compatible con Merge Sort\n",
    "        lista_promedios.append((ciudad, anio, promedio))\n",
    "\n",
    "    return lista_promedios\n",
    "\n",
    "# --- LÓGICA DE PROCESAMIENTO (CON MULTIPROCESAMIENTO) ---\n",
    "\n",
    "def process_chunk(chunk):\n",
    "    \"\"\"\n",
    "    Realiza la limpieza a nivel de fila de forma paralela y devuelve filas limpias.\n",
    "    \"\"\"\n",
    "    if chunk.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        chunk = chunk.copy()\n",
    "\n",
    "        # 1. Limpieza y conversión a numérico\n",
    "        chunk['AvgTemperature'] = chunk['AvgTemperature'].replace(r'[\"\\(\\)-]', '', regex=True)\n",
    "        chunk['AvgTemperature'] = pd.to_numeric(chunk['AvgTemperature'], errors='coerce')\n",
    "\n",
    "        # 2. Limpieza de fecha y extracción del año\n",
    "        chunk['Fecha'] = chunk['Fecha'].replace(r'[\"\\(\\)]', '', regex=True)\n",
    "        chunk = chunk.dropna(subset=['AvgTemperature', 'Fecha'])\n",
    "        chunk['Year'] = chunk['Fecha'].str.split('/').str[2]\n",
    "        chunk = chunk.dropna(subset=['Year'])\n",
    "\n",
    "        # 3. Filtrado extremo\n",
    "        chunk = chunk[chunk['AvgTemperature'] > -90]\n",
    "\n",
    "        # 4. Devolver las columnas necesarias para el cálculo del promedio:\n",
    "        return chunk[['City', 'Year', 'AvgTemperature']]\n",
    "\n",
    "    except Exception as e:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def parallel_processing_with_chunks(chunks_to_process, func):\n",
    "    \"\"\"\n",
    "    Divide y mapea la función 'func' a los chunks en paralelo.\n",
    "    \"\"\"\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    print(f\"\\n[PROCESAMIENTO PARALELO] Usando {num_cores} núcleos para {len(chunks_to_process)} bloques.\")\n",
    "\n",
    "    with multiprocessing.Pool(num_cores) as pool:\n",
    "        results = pool.map(func, chunks_to_process)\n",
    "\n",
    "    return results\n",
    "\n",
    "# --- FUNCIÓN PRINCIPAL (MAIN) ---\n",
    "\n",
    "def main():\n",
    "    tiempo_INICIAL = time.time()\n",
    "    archivo_entrada = 'temperaturas.csv'\n",
    "    archivo_salida = 'procesamiento_paralelo_python_promedios.csv'\n",
    "    CHUNK_SIZE = 100000\n",
    "\n",
    "    print(\"\\n=======================================================\")\n",
    "    print(\"Iniciando Cálculo de Promedios Anuales por Ciudad\")\n",
    "    print(\"=======================================================\")\n",
    "\n",
    "    # 1. LECTURA POR CHUNKS Y LIMPIEZA PARALELA\n",
    "    print(\"\\n[PASO 1] Leyendo y Limpiando filas crudas en paralelo...\")\n",
    "    start_lectura = time.time()\n",
    "    chunks = []\n",
    "    try:\n",
    "        csv_iterator = pd.read_csv(\n",
    "            archivo_entrada,\n",
    "            usecols=['City', 'AvgTemperature', 'Fecha'],\n",
    "            chunksize=CHUNK_SIZE,\n",
    "            encoding='utf-8',\n",
    "            low_memory=True,\n",
    "            skip_blank_lines=True\n",
    "        )\n",
    "        for chunk in csv_iterator:\n",
    "            chunks.append(chunk)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n ERROR: Al leer el archivo {archivo_entrada}. Detalles: {e}\")\n",
    "        return\n",
    "    \n",
    "    results = parallel_processing_with_chunks(chunks, process_chunk)\n",
    "    valid_results = [res for res in results if not res.empty]\n",
    "    if not valid_results:\n",
    "        print(\"\\n Advertencia: No se obtuvieron datos válidos de los procesos paralelos.\")\n",
    "        return\n",
    "\n",
    "    # Consolidar todos los DataFrames de filas limpias\n",
    "    final_df_limpio = pd.concat(valid_results, ignore_index=True)\n",
    "    \n",
    "    # Convertir el DataFrame a lista de tuplas para el algoritmo de agregación\n",
    "    data_list_limpia = final_df_limpio.to_records(index=False).tolist()\n",
    "    end_lectura = time.time()\n",
    "    \n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(f\"   Tiempo de lectura y limpieza paralela: {end_lectura - start_lectura:.4f} segundos\")\n",
    "    print(f\"   Filas crudas válidas consolidadas: {len(data_list_limpia):,} filas.\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    # 2. CÁLCULO DE PROMEDIOS ANUALES (se implementa la formula)\n",
    "    print(\"\\n[PASO 2] Aplicando Fórmula de Promedio Anual...\")\n",
    "    start_promedios = time.time()\n",
    "    \n",
    "    # Se utiliza la lista limpia y se aplica la lógica de agregación\n",
    "    # El resultado es la lista de promedios anuales\n",
    "    arr_promedios = calcular_promedios_anuales(data_list_limpia)\n",
    "    \n",
    "    end_promedios = time.time()\n",
    "    \n",
    "    print(f\"  Tiempo de cálculo de promedios: {end_promedios - start_promedios:.4f} segundos\")\n",
    "    print(f\"  Registros de promedios anuales: {len(arr_promedios):,} registros (Resultado de la agregación).\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    # 3. DEPURACIÓN NIVEL 2 (QuickSort)\n",
    "    print(\"\\n[PASO 3] Depuración (QuickSort-style) de los promedios...\")\n",
    "    start_depuracion = time.time()\n",
    "    n_validos = depurar_y_particionar(arr_promedios)\n",
    "    arr_depurado = arr_promedios[:n_validos]\n",
    "    end_depuracion = time.time()\n",
    "    print(f\"   Tiempo de depuración: {end_depuracion - start_depuracion:.4f} segundos\")\n",
    "    print(f\"   Promedios finales a ordenar: {n_validos:,} registros.\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    # 4. ORDENAMIENTO (Merge Sort)\n",
    "    print(\"\\n[PASO 4] Ordenamiento (Merge Sort) de los promedios...\")\n",
    "    start_merge = time.time()\n",
    "    datos_ordenados = merge_sort(arr_depurado)\n",
    "    end_merge = time.time()\n",
    "    print(f\"  Tiempo de ordenamiento: {end_merge - start_merge:.4f} segundos\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    # 5. ESCRITURA DE REPORTE\n",
    "    print(f\"\\n[PASO 5] Generando archivo CSV: {archivo_salida}\")\n",
    "    start_escritura = time.time()\n",
    "    try:\n",
    "        with open(archivo_salida, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['Anio', 'Ciudad', 'TemperaturaPromedio'])\n",
    "            \n",
    "            for row in datos_ordenados:\n",
    "                ciudad, anio, temp = row\n",
    "                writer.writerow([anio, f'\"{ciudad}\"', f'{temp:.2f}'])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n ERROR: Al escribir el archivo. Detalles: {e}\")\n",
    "        return\n",
    "    end_escritura = time.time()\n",
    "    print(f\"  Tiempo de escritura: {end_escritura - start_escritura:.4f} segundos\")\n",
    "\n",
    "\n",
    "    tiempo_FINAL = time.time()\n",
    "    print(\"\\n=======================================================\")\n",
    "    print(f\" PROCESO COMPLETADO. Tiempo total: {tiempo_FINAL - tiempo_INICIAL:.4f} segundos.\")\n",
    "    print(\"=======================================================\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    multiprocessing.freeze_support()\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
