{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbea103f-df5c-45dd-9718-806079f7449f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "Iniciando Procesamiento Paralelo y Ordenamiento de Datos\n",
      "=======================================================\n",
      "\n",
      "[PASO 1] Leyendo archivo CSV...\n",
      "   Tiempo de lectura: 0.8723 segundos\n",
      "   Filas totales cargadas: 1,048,575 registros.\n",
      "-------------------------------------------------------\n",
      "\n",
      "[PROCESAMIENTO PARALELO] Usando 8 n煤cleos para 11 bloques.\n",
      "-------------------------------------------------------\n",
      "   Tiempo de limpieza paralelo: 2.3733 segundos\n",
      "   Registros limpios (listos para ordenar): 992,090 filas.\n",
      "\n",
      "[PASO 2] Ч Depuraci贸n (QuickSort-style)...\n",
      "   Tiempo de depuraci贸n: 0.3238 segundos\n",
      "   Registros finales a ordenar: 992,007 filas.\n",
      "-------------------------------------------------------\n",
      "\n",
      "[PASO 3] Ordenamiento (Merge Sort)...\n",
      "   Tiempo de ordenamiento: 7.0409 segundos\n",
      "-------------------------------------------------------\n",
      "\n",
      "[PASO 4] Generando archivo CSV: procesamiento_paralelo_python_ordenado.csv\n",
      "   Tiempo de escritura: 2.2952 segundos\n",
      "\n",
      "=======================================================\n",
      " PROCESO COMPLETADO. Tiempo total: 13.5415 segundos.\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import time\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "from itertools import chain\n",
    "\n",
    "# Aumentar el l铆mite del campo CSV, esencial para archivos grandes\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "# Soluci贸n al SettingWithCopyWarning: Desactivamos la advertencia para que no interfiera\n",
    "# en la salida, ya que la l贸gica en process_chunk ya usa una copia segura.\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# --- ALGORITMOS DE ORDENAMIENTO Y DEPURACIN ---\n",
    "\n",
    "def merge_sort(arr):\n",
    "    if len(arr) <= 1:\n",
    "        return arr\n",
    "    mid = len(arr) // 2\n",
    "    left = merge_sort(arr[:mid])\n",
    "    right = merge_sort(arr[mid:])\n",
    "    return merge(left, right)\n",
    "\n",
    "def merge(left, right):\n",
    "    result = []\n",
    "    i = j = 0\n",
    "    while i < len(left) and j < len(right):\n",
    "        # Criterio de ordenamiento: de mayor a menor temperatura (ndice 2)\n",
    "        if left[i][2] >= right[j][2]:\n",
    "            result.append(left[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            result.append(right[j])\n",
    "            j += 1\n",
    "    result.extend(left[i:])\n",
    "    result.extend(right[j:])\n",
    "    return result\n",
    "\n",
    "# Quick Sort-style para depurar: filtra valores no num茅ricos o 0.0\n",
    "def depurar_y_particionar(arr):\n",
    "    n = len(arr)\n",
    "    i = -1\n",
    "    for j in range(n):\n",
    "        temp_val = arr[j][2]\n",
    "        if isinstance(temp_val, (int, float)) and temp_val != 0.0:\n",
    "            i += 1\n",
    "            arr[i], arr[j] = arr[j], arr[i]\n",
    "    return i + 1\n",
    "\n",
    "# --- LGICA DE PROCESAMIENTO (CON MULTIPROCESAMIENTO) ---\n",
    "\n",
    "def process_chunk(chunk):\n",
    "    \n",
    "    #Realiza la limpieza a nivel de fila de forma paralela.\n",
    "    \n",
    "    if chunk.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        # Soluci贸n al SettingWithCopyWarning: Trabajamos con una copia expl铆cita para evitar la advertencia\n",
    "        chunk = chunk.copy()\n",
    "\n",
    "        # 1. Depuraci贸n Nivel 1 (Guiones y Cadenas a NaN)\n",
    "        chunk['AvgTemperature'] = chunk['AvgTemperature'].replace(r'[\"\\(\\)-]', '', regex=True)\n",
    "        chunk['AvgTemperature'] = pd.to_numeric(chunk['AvgTemperature'], errors='coerce')\n",
    "\n",
    "        # 2. Limpieza de fecha\n",
    "        chunk['Fecha'] = chunk['Fecha'].replace(r'[\"\\(\\)]', '', regex=True)\n",
    "\n",
    "        # 3. Eliminar filas con NaN en temperatura o fecha\n",
    "        chunk = chunk.dropna(subset=['AvgTemperature', 'Fecha'])\n",
    "\n",
    "        # 4. Extraer el a帽o\n",
    "        chunk['Year'] = chunk['Fecha'].str.split('/').str[2]\n",
    "        chunk = chunk.dropna(subset=['Year'])\n",
    "\n",
    "        # 5. Filtrado de temperaturas extremas\n",
    "        chunk = chunk[chunk['AvgTemperature'] > -90]\n",
    "\n",
    "        # 6. Devolver las columnas necesarias para el ordenamiento\n",
    "        return chunk[['City', 'Year', 'AvgTemperature']]\n",
    "\n",
    "    except Exception as e:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def parallel_processing_with_chunks(chunks_to_process, func):\n",
    "    \n",
    "    #Divide y mapea la funci贸n 'func' a los chunks en paralelo.\n",
    "    \n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    print(f\"\\n[PROCESAMIENTO PARALELO] Usando {num_cores} n煤cleos para {len(chunks_to_process)} bloques.\")\n",
    "\n",
    "    with multiprocessing.Pool(num_cores) as pool:\n",
    "        results = pool.map(func, chunks_to_process)\n",
    "\n",
    "    return results\n",
    "\n",
    "# --- FUNCIN PRINCIPAL (MAIN) ---\n",
    "\n",
    "def main():\n",
    "    tiempo_INICIAL = time.time()\n",
    "    archivo_entrada = 'temperaturas.csv'\n",
    "    archivo_salida = 'procesamiento_paralelo_python_ordenado.csv'\n",
    "    CHUNK_SIZE = 100000 # Un valor m谩s grande para archivos grandes\n",
    "\n",
    "    print(\"\\n=======================================================\")\n",
    "    print(\"Iniciando Procesamiento Paralelo y Ordenamiento de Datos\")\n",
    "    print(\"=======================================================\")\n",
    "\n",
    "    # 1. LECTURA POR CHUNKS\n",
    "    print(\"\\n[PASO 1] Leyendo archivo CSV...\")\n",
    "    start_lectura = time.time()\n",
    "    chunks = []\n",
    "    try:\n",
    "        csv_iterator = pd.read_csv(\n",
    "            archivo_entrada,\n",
    "            usecols=['City', 'AvgTemperature', 'Fecha'],\n",
    "            chunksize=CHUNK_SIZE,\n",
    "            encoding='utf-8',\n",
    "            low_memory=True,\n",
    "            skip_blank_lines=True\n",
    "        )\n",
    "        for chunk in csv_iterator:\n",
    "            chunks.append(chunk)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n ERROR: Al leer el archivo {archivo_entrada}. Detalles: {e}\")\n",
    "        return\n",
    "\n",
    "    end_lectura = time.time()\n",
    "    total_filas_crudas = sum(len(c) for c in chunks)\n",
    "    print(f\"   Tiempo de lectura: {end_lectura - start_lectura:.4f} segundos\")\n",
    "    print(f\"   Filas totales cargadas: {total_filas_crudas:,} registros.\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    # 2. PROCESAMIENTO PARALELO (Limpieza)\n",
    "    start_procesamiento = time.time()\n",
    "    results = parallel_processing_with_chunks(chunks, process_chunk)\n",
    "    valid_results = [res for res in results if not res.empty]\n",
    "\n",
    "    if not valid_results:\n",
    "        print(\"\\n Advertencia: No se obtuvieron datos v谩lidos de los procesos paralelos.\")\n",
    "        return\n",
    "\n",
    "    final_df = pd.concat(valid_results, ignore_index=True)\n",
    "    end_procesamiento = time.time()\n",
    "    \n",
    "    data_list = final_df.to_records(index=False).tolist()\n",
    "    \n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(f\"   Tiempo de limpieza paralelo: {end_procesamiento - start_procesamiento:.4f} segundos\")\n",
    "    print(f\"   Registros limpios (listos para ordenar): {len(data_list):,} filas.\")\n",
    "\n",
    "\n",
    "    # 3. DEPURACIN NIVEL 2 (QuickSort-style)\n",
    "    print(\"\\n[PASO 2] Depuraci贸n (QuickSort-style)...\")\n",
    "    start_depuracion = time.time()\n",
    "    n_validos = depurar_y_particionar(data_list)\n",
    "    arr_depurado = data_list[:n_validos]\n",
    "    end_depuracion = time.time()\n",
    "    print(f\"   Tiempo de depuraci贸n: {end_depuracion - start_depuracion:.4f} segundos\")\n",
    "    print(f\"   Registros finales a ordenar: {n_validos:,} filas.\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    # 4. ORDENAMIENTO (Merge Sort)\n",
    "    print(\"\\n[PASO 3] Ordenamiento (Merge Sort)...\")\n",
    "    start_merge = time.time()\n",
    "    datos_ordenados = merge_sort(arr_depurado)\n",
    "    end_merge = time.time()\n",
    "    print(f\"   Tiempo de ordenamiento: {end_merge - start_merge:.4f} segundos\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    # 5. ESCRITURA DE REPORTE\n",
    "    print(f\"\\n[PASO 4] Generando archivo CSV: {archivo_salida}\")\n",
    "    start_escritura = time.time()\n",
    "    try:\n",
    "        # Soluci贸n de Codificaci贸n: Usar encoding='utf-8' de forma expl铆cita\n",
    "        with open(archivo_salida, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['Anio', 'Ciudad', 'TemperaturaPromedio'])\n",
    "\n",
    "            for row in datos_ordenados:\n",
    "                ciudad, anio, temp = row\n",
    "                writer.writerow([anio, f'\"{ciudad}\"', f'{temp:.2f}'])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n ERROR: Al escribir el archivo. Aseg煤rese de que el sistema soporte UTF-8. Detalles: {e}\")\n",
    "        return\n",
    "    end_escritura = time.time()\n",
    "    print(f\"   Tiempo de escritura: {end_escritura - start_escritura:.4f} segundos\")\n",
    "\n",
    "\n",
    "    tiempo_FINAL = time.time()\n",
    "    print(\"\\n=======================================================\")\n",
    "    print(f\" PROCESO COMPLETADO. Tiempo total: {tiempo_FINAL - tiempo_INICIAL:.4f} segundos.\")\n",
    "    print(\"=======================================================\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    multiprocessing.freeze_support()\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
